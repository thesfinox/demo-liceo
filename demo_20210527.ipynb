{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725c64c4-7a83-4da3-b7e6-bc30c2038d56",
   "metadata": {},
   "source": [
    "# Intelligenza Artificiale tra Geometria e Fisica\n",
    "\n",
    "> Autore: [Riccardo Finotello](mailto:riccardo.finotello@gmail.com)\n",
    ">\n",
    "> Codice disponibile su [GitHub](https://github.com/thesfinox/demo-liceo).\n",
    "\n",
    "In questa dimostrazione l'idea è di costruire un piccolo modello di **Intelligenza Artificiale** in grado di riconoscere **cifre scritte a mano**.\n",
    "\n",
    "La dimostrazione, per motivi didattici, è tuttavia *divisa in due parti*:\n",
    "\n",
    "1. la **prima parte** introduce un semplice compito risolvibile con **Machine Learning** nel senso classico del termine,\n",
    "2. la **seconda parte** prevede l'uso di metodi più avanzati per costruire una **AI** funzionante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13355bf9-55af-4457-a7cb-ef1ae313b115",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, Conv2DTranspose, GlobalMaxPool2D, MaxPool2D, Activation, UpSampling2D\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy, BinaryAccuracy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from IPython.display import Image\n",
    "from utils.utils import *\n",
    "from utils.plots import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# set the random seed\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "# set memory growth\n",
    "set_memory_growth()\n",
    "\n",
    "# set random seed\n",
    "rs = np.random.RandomState(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db06dfa-f1e0-49d8-bed4-48f853c4190c",
   "metadata": {},
   "source": [
    "## Machine Learning\n",
    "\n",
    "Il primo compito che affrontiamo è quello di **classificare** dei fiori nelle loro diverse **specie** date le loro **caratteristiche**.\n",
    "\n",
    "> L'idea è mostrare che MACHINE LEARNING = TRASFORMAZIONE in modo tale da avere una **rappresentazione conveniente** per poter suddividere gli elementi nelle loro **classi**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522d69be-e354-4894-87d3-90e57758ebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Iris dataset\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "\n",
    "# divide train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.6, shuffle=True, random_state=rs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8e801b-8ae3-4d67-8118-1ff938527902",
   "metadata": {},
   "source": [
    "Come ogni buon **data scientist**, prima di tutto osserviamo i dati per renderci conto cosa abbiamo di fronte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01467657-fdd6-4f25-bc30-d810666304ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first 10 entries\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b708d0-fa30-4482-877f-6205d5a82496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide the target labels (with names)\n",
    "names        = {0: 'setosa', 1: 'versicolor', 2: 'virginica'}\n",
    "y_test_dummy = pd.get_dummies(y_test.replace(names)).values\n",
    "\n",
    "# show the first 10 labels\n",
    "y_train.replace(names).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0b4dae-d949-44e2-8557-fa9ad878beb1",
   "metadata": {},
   "source": [
    "### Approccio \"Unsupervised\"\n",
    "\n",
    "Il primo approccio che utilizzeremo è di tipo **unsupervised**. In altre parole, non forniamo alla macchina le risposte, ma ci aspettiamo che la macchina riesca a *trovare un senso* nei dati, ossia riesca a distinguere per noi se alcuni dati sono *diversi* da altri.\n",
    "\n",
    "> Un approccio **unsupervised** non è in generale in grado di generare *la risposta* al problema! Fornisce una linea guida, dal quale poi proseguire. Non essendo a conoscenza del risultato *giusto* è infatti difficile poter ottenere *la risposta*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ef510-6d23-4766-b582-dc2273213b54",
   "metadata": {},
   "source": [
    "#### Clustering\n",
    "\n",
    "Uno degli algoritmi più diffusi per sondare la **struttura** dei dati è un algoritmo di *clustering*. Il suo compito è formare dei **gruppi** di dati simili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2cd1e5-606f-43db-9076-c29c7b410fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=rs)\n",
    "t_labs = pd.Series(kmeans.fit_predict(X_train), name='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3280609c-fff6-480b-ba51-402b9f992f79",
   "metadata": {},
   "source": [
    "#### Visualizzazione con PCA\n",
    "\n",
    "Abbiamo visto prima che i dati in ingresso sono dei **vettori con 4 dimensioni**. Questo significa che, in generale, disegnare questi dati su un grafico risulta essere un compito impossibile. Esistono tuttavia altri metodi **unsupervised** che **riducono la dimensionalità** dei vettori. Il loro compito è duplice:\n",
    "\n",
    "1. possono essere usati per ridurre i dati a disposizione, cercando di estrarre solo quelli **più significativi**,\n",
    "2. possono essere usati per ridurre a 2 le dimensioni dei dati.\n",
    "\n",
    "In questo primo tentativo noi useremo **PCA** (*Principal Components Analysis*) per ridurre a 2 dimensioni i dati e disegnare i grafici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c059141-ad51-4bcd-9a68-6e31a28d0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensionality with PCA\n",
    "pca  = PCA(n_components=2, random_state=rs)\n",
    "t_cp = pd.DataFrame(pca.fit_transform(X_train), columns=['pc_1', 'pc_2'])\n",
    "d_cp = pd.DataFrame(pca.transform(X_test), columns=['pc_1', 'pc_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f221b1f4-6a68-468e-9107-ceac49931cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(t_cp,\n",
    "                            'pc_1',\n",
    "                            'pc_2',\n",
    "                            labs=(t_labs, 3),\n",
    "                            xlab='PC 1',\n",
    "                            ylab='PC 2',\n",
    "                            title='Iris Dataset - KMeans Clustering - PCA',\n",
    "                            pal='hls',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714133e-1a8d-4188-af87-94163177df3a",
   "metadata": {},
   "source": [
    "#### Visualizzazione con TSNE\n",
    "\n",
    "PCA tuttavia non è il solo algoritmo in grado di fare questo. Un altro metodo interessante si chiama **t-SNE**, ed anziché trasformare geometricamente i dati, esso cerca di *imparare* la forma dello spazio migliore per **rappresentare i dati**. In pratica opera \"cambiando la forza di gravità\" dello spazio e ne modifica la forma, proprio come la **forza di gravità*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb069918-4986-4fde-8157-b6be610d20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute manifold learning with tSNE\n",
    "tsne  = TSNE(n_components=2, random_state=rs, n_jobs=-1)\n",
    "t_rep = pd.DataFrame(tsne.fit_transform(X_train), columns=['tsne_1', 'tsne_2'])\n",
    "d_rep = pd.DataFrame(tsne.fit_transform(X_test), columns=['tsne_1', 'tsne_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec56f2a-ab81-4eef-a6ba-7285533b0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(t_rep,\n",
    "                            'tsne_1',\n",
    "                            'tsne_2',\n",
    "                            labs=(t_labs, 3),\n",
    "                            xlab='TSNE 1',\n",
    "                            ylab='TSNE 2',\n",
    "                            title='Iris Dataset - KMeans Clustering - TSNE',\n",
    "                            pal='hls',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82f53a3-2197-4618-b6f9-f00c89686088",
   "metadata": {},
   "source": [
    "#### Feature Engineering e Data Science\n",
    "\n",
    "Non soddisfatti? Proviamo a **generare** un maggior numero di dati **a partire da ciò che abbiamo**. Molto probabilmente la macchina non è in grado di sfruttare al massimo l'informazione contenuta nei dati.\n",
    "\n",
    "> In **data science** così come la **fisica** il \"codice\" (o la formula) non sono mai sufficienti, ma è necessario **sempre** un grande lavoro di raccolta e analisi dei dati. L'informazione è infatti solitamente nascosta. L'uso dell'intelligenza artificiale può solo **mitigare** il problema, ma in generale è meglio affrontarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e508dcd1-dbf7-44d0-a7be-2d0c5f732d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create polynomial features\n",
    "pol              = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_enhanced = pol.fit_transform(X_train)\n",
    "\n",
    "print(f'New shape of the data: {X_train_enhanced.shape}')\n",
    "\n",
    "# fit KMeans\n",
    "t_labs_enhanced = pd.Series(kmeans.fit_predict(X_train_enhanced), name='target')\n",
    "\n",
    "# compute manifold learning with tSNE\n",
    "tsne_enhanced  = TSNE(n_components=2, random_state=rs, n_jobs=-1)\n",
    "t_rep_enhanced = pd.DataFrame(tsne.fit_transform(X_train_enhanced), columns=['tsne_1', 'tsne_2'])\n",
    "\n",
    "# plot the result\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(t_rep_enhanced,\n",
    "                            'tsne_1',\n",
    "                            'tsne_2',\n",
    "                            labs=(t_labs_enhanced, 3),\n",
    "                            xlab='TSNE 1',\n",
    "                            ylab='TSNE 2',\n",
    "                            title='Iris Dataset (enhanced) - KMeans Clustering - TSNE',\n",
    "                            pal='hls',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57501235-98d7-4b43-80ee-7b104a399654",
   "metadata": {},
   "source": [
    "### Approccio \"Supervised\"\n",
    "\n",
    "L'approccio **supervised** è forse il più intuitivo da comprendere.\n",
    "Si tratta dopotutto di *imparare* qualcosa attraverso una grande serie di **errori** e **correzioni**.\n",
    "Alla macchina in questo caso vengono fornite **alcune** risposte corrette: viene individuato un sottoinsieme di elementi che vengono usati per *imparare* qualcosa, mentre altri elementi vengono utilizzati per *controllare* che la macchina stia imparando correttamente.\n",
    "\n",
    "> Spesso la macchina tende a riprodurre un risultato senza realmente \"capire\" cosa sta facendo. Pertanto è **molto** importante sempre avere una strategia di *validazione* che funzioni ed usarla correttamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d43e47-a457-4291-b8cb-82f7af175cda",
   "metadata": {},
   "source": [
    "#### Curva logistica\n",
    "\n",
    "La curva logistica è alla base di un mucchio di applicazionie, quali biologia, fisica, finanza, etc.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)\n",
    "\n",
    "In questo contensto viene usata per modellizzare una **probabilità**, dato che assegna un numero nell'intervallo $[0, 1]$ a dei numeri reali.\n",
    "\n",
    "> Il concetto di probabilità è estremamente importante. La macchina infatti, durante il suo apprendimento, impara a gestire con quale probabilità è atteso un certo risultato, e sceglie di conseguenza.\n",
    "\n",
    "Da notare che, soprattutto nel caso delle reti neurali, diversi tentativi sono stati fatti per cercare di capire *come* la macchina impari.\n",
    "Questo tipo di studi è condotto utilizzando delle modellizzazioni provenienti dalla **fisica** (teorica in particolare) come lo studio della *teoria dei campi* e delle *matrici casuali*.\n",
    "\n",
    "> È infatti estremamente interessante cercare di capire il legame tra Intelligenza Artificiale e la Fisica, dato che molti elementi sono effettivamente in comune e possono portare ad una migliore comprensione di *come* l'AI funziona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afa3124-ae3f-4940-9d7d-06f481d3d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute logistic regression\n",
    "lr = LogisticRegression(C=1.0e5, n_jobs=-1)\n",
    "lr = lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e46157c-9b5c-4ab2-8560-db3775d9d91b",
   "metadata": {},
   "source": [
    "Avendo \"allenato\" la macchina su alcuni elementi, ora procediamo a predire il risultato su **quelli che non sono mai stati visti** dalla macchina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12626f47-db27-4138-ab5c-7f4a9f36d55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred = pd.Series(lr.predict(X_test), name='prediction')\n",
    "y_prob = lr.predict_proba(X_test)\n",
    "ident  = pd.Series(y_pred.values == y_test.values, name='test').replace({True: 'ok', False: 'wrong'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff36647a-812f-4ea1-8385-54e63cae5038",
   "metadata": {},
   "source": [
    "#### Visualizzazione con PCA\n",
    "\n",
    "Come in precedenza, procediamo a *ridurre la dimensionalità* dei vettori in ingresso e guardiamo il risultato. Questa volta è disponibile la *verità* (in Inglese, **ground truth**) per confrontare quanto l'algoritmo stia imparando bene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94516297-b6ac-49d8-a694-609b9d4a37cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(d_cp,\n",
    "                            'pc_1',\n",
    "                            'pc_2',\n",
    "                            labs=(y_pred.replace(names), 3),\n",
    "                            style=ident,\n",
    "                            xlab='PC 1',\n",
    "                            ylab='PC 2',\n",
    "                            title='Iris Dataset - Logistic Regression - PCA',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196652da-8a2d-4adf-b2b4-98019b0970ba",
   "metadata": {},
   "source": [
    "#### Efficacia della classificazione\n",
    "\n",
    "L'efficacia del processo di apprendimento può e deve essere **misurata** con delle funzioni che vengono chiamate *metriche* (in questo caso, non sono quelle della fisica).\n",
    "\n",
    "In questo caso ne scegliamo più di una:\n",
    "\n",
    "1. **accuratezza**: \\begin{equation} \\frac{\\text{predizioni corrette}}{\\text{numero di predizioni}} \\end{equation}\n",
    "2. **precisione**: \\begin{equation} \\frac{\\text{positivi veri}}{\\text{totale di positivi predetti}} \\end{equation}\n",
    "3. **recall** (o *true positive rate*): \\begin{equation} \\frac{\\text{positivi veri}}{\\text{totale di positivi effettivi}} \\end{equation}\n",
    "\n",
    "In sostanza, l'**accuratezza** misura la bontà generale della predizione, la **precisione** quante volte la predizione \"positiva\" è corretta, il **recall** quante volte riuscite a predire la classe positiva.\n",
    "\n",
    "Per intenderci, supponete di voler predire se il risultato di un test è positivo: se il vostro test predice correttamente un gran numero di positivi, allora è **preciso**; se il vostro test non si lascia mai sfuggire un positivo, allora ha un grande **recall**. È da notare che tuttavia queste metriche non sono indipendenti: un test **molto preciso** avrà **basso recall**, e viceversa.\n",
    "\n",
    "L'accuratezza gioca un ruolo particolare. Supponete che il numero di positivi sia solo l'1% del totale. Se la vostra macchina predice sempre *negativo*, qual è la sua accuratezza? È un test attendibile? Cosa si può dire di precisione e recall?\n",
    "\n",
    "[RISPOSTE: 99%; NO; BASSA PRECISIONE, BASSO RECALL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3e5d1c-fb6f-4444-81c4-4a36232c0de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {100 * acc:.2f}%')\n",
    "\n",
    "pre = precision_score(y_test, y_pred, average='micro')\n",
    "print(f'Precision: {100 * pre:.2f}%')\n",
    "\n",
    "rec = recall_score(y_test, y_pred, average='micro')\n",
    "print(f'Recall: {100 * pre:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a018b1a-6b1f-4312-afd0-9a2bd85155c2",
   "metadata": {},
   "source": [
    "Per meglio illustrare la dipendenza delle due metriche, possiamo studiare la loro variabilità in funzione di diverse soglie sulla probabilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc9dd1-dbc9-4b7c-b342-67b531a7c9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, _ = precision_recall_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_precision_recall(p, r, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676b4d5e-b88e-4180-9e98-1628aef7d0d7",
   "metadata": {},
   "source": [
    "Una maniera per ovviare al problema può essere studiare *cumulativamente* gli effetti delle due metriche, calcolando l'area della curva sottesa dal numero veri positivi e il numero di falsi positivi. La curva è nota come **Receiver Operating Characteristic** (ROC). Più l'area si avvicina a $1$, migliore è la predizione, mentre $0.5$ (la diagonale nel grafico) rappresenta un classificatore che tira a infovinare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accabc34-9286-4658-8b30-78dd0cd8a232",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "score       = roc_auc_score(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_roc_curve(fpr, tpr, score, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6d8bba-3e32-45c8-ac25-051619bc7f6d",
   "metadata": {},
   "source": [
    "### Unsupervised + Supervised\n",
    "\n",
    "Gli approcci *supervised* e *unsupervised* non sono esclusivi, ma possono essere combinati tra loro.\n",
    "Ad esempio, considerate due casi molto diversi ma con un'idea di fondo simile:\n",
    "\n",
    "- avete a disposizione $10^6$ di vettori di dimensione $100$ e volete cercare di predire una particolare classe: potete usare un algoritmo **unsupervised** per ridurre il numero di dati, e poi calcolare la classificazione **supervised**;\n",
    "- avete a disposizione molti segnali acustici corrotti da molto rumore: usate un algoritmo **unsupervised** per *pulire* i dati, ed operate successivamente **supervised** per calcolare la quantità desiderata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b820732-5fc9-4201-b3ab-58490538316b",
   "metadata": {},
   "source": [
    "#### Curva logistica + TSNE\n",
    "\n",
    "Il primo tentativo che faremo è di \"allenare\" una curva logistica sui dati t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb106a7-8fd7-4f93-a6e1-64bb29ed027a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0e5, n_jobs=-1)\n",
    "lr = lr.fit(t_rep, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67e7879-9364-4656-81a6-59f21c4356b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(lr.predict(d_rep), name='prediction')\n",
    "y_prob = lr.predict_proba(d_rep)\n",
    "ident  = pd.Series(y_pred.values == y_test.values, name='test').replace({True: 'ok', False: 'wrong'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd737416-9bc0-42a3-ad9b-ddc79339c227",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(d_rep,\n",
    "                            'tsne_1',\n",
    "                            'tsne_2',\n",
    "                            labs=(y_pred.replace(names), 3),\n",
    "                            style=ident,\n",
    "                            xlab='TSNE 1',\n",
    "                            ylab='TSNE 2',\n",
    "                            title='Iris Dataset (TSNE reduced) - Logistic Regression',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c164ae7-12bc-4aac-bd2d-0cd47d0c415c",
   "metadata": {},
   "source": [
    "Il grafico parla da sé: l'aver *perso* dell'informazione per strada ha fatto sì che la classificazione abbia perso molto in accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791291ce-e2fa-4a84-98d7-b0c4667b63a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {100 * acc:.2f}%')\n",
    "\n",
    "pre = precision_score(y_test, y_pred, average='micro')\n",
    "print(f'Precision: {100 * pre:.2f}%')\n",
    "\n",
    "rec = recall_score(y_test, y_pred, average='micro')\n",
    "print(f'Recall: {100 * pre:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8a3fa-282c-4845-a6ba-098e30eb9326",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, _ = precision_recall_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_precision_recall(p, r, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee54bf-161b-4aba-ac8d-7931db99f1cf",
   "metadata": {},
   "source": [
    "Tanto è vero che, a questo punto, il machine learning non è meglio che tirare a indovinare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab3f3d-4916-45a7-b33f-a7dffdf6ec30",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "score       = roc_auc_score(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_roc_curve(fpr, tpr, score, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b2a13d-0881-4931-b1ec-820476b600bd",
   "metadata": {},
   "source": [
    "Un modo per cercare di capire cosa il machine learning stia facendo è studiare i **contorni decisionali** (in Inglese, *decision boundaries*), ossia dove la macchina divide una classe dall'altra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbae706-fef5-4335-a23a-786f1640996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(d_rep['tsne_1'].min() - 5.0, d_rep['tsne_1'].max() + 5.0, 0.1)\n",
    "y = np.arange(d_rep['tsne_2'].min() - 5.0, d_rep['tsne_2'].max() + 5.0, 0.1)\n",
    "x_grid, y_grid = np.meshgrid(x, y)\n",
    "grid = np.c_[x_grid.ravel(), y_grid.ravel()]\n",
    "bnd  = lr.predict(grid).reshape(x_grid.shape)\n",
    "\n",
    "fig, ax = subplots()\n",
    "\n",
    "c = ax.contourf(x_grid,\n",
    "                y_grid,\n",
    "                bnd,\n",
    "                levels=range(-1, 3),\n",
    "                colors=[sns.color_palette(n_colors=3)[i] for i in [0, 2, 1]],\n",
    "                alpha=0.3\n",
    "               )\n",
    "\n",
    "cbar = fig.colorbar(c, ticks=np.arange(3) - 0.5, ax=ax)\n",
    "cbar.set_ticklabels(names)\n",
    "\n",
    "sns.scatterplot(data=d_rep,\n",
    "                x='tsne_1',\n",
    "                y='tsne_2',\n",
    "                hue=y_pred.replace(names),\n",
    "                style=ident,\n",
    "                ax=ax\n",
    "               )\n",
    "\n",
    "ax.set(xlabel='TSNE 1', ylabel='TSNE 2', title='TSNE + LogReg')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7b9a5-0958-40a3-8379-9fd85002b03b",
   "metadata": {},
   "source": [
    "In questo caso la rappresentazione data in input non è la migliore. Il machine learning, infatti, non riesce a suddividere correttamente in classi i vari elementi, finendo per sbagliare completamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4b7ea4-2bbe-4a67-9738-401e43c2ebcf",
   "metadata": {},
   "source": [
    "#### Curva logistica + PCA\n",
    "\n",
    "Proviamo ora a cambiare il tipo di trasformazione in input per vedere se riusciamo a trovarne una più adatta. Proviamo ora ad utilizzare **PCA** per rasformare i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418cafa5-0ce5-486b-a298-7439cd459ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0e5, n_jobs=-1)\n",
    "lr = lr.fit(t_cp, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78b501-f243-4c36-8297-d443bb830f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pd.Series(lr.predict(d_cp), name='prediction')\n",
    "y_prob = lr.predict_proba(d_cp)\n",
    "ident  = pd.Series(y_pred.values == y_test.values, name='test').replace({True: 'ok', False: 'wrong'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aec811-e632-4ff9-b0ca-bc9cfbfd2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots()\n",
    "\n",
    "plot_dimensionality_reduced(d_cp,\n",
    "                            'pc_1',\n",
    "                            'pc_2',\n",
    "                            labs=(y_pred.replace(names), 3),\n",
    "                            style=ident,\n",
    "                            xlab='PC 1',\n",
    "                            ylab='PC 2',\n",
    "                            title='Iris Dataset (PCA reduced) - Logistic Regression',\n",
    "                            ax=ax\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f8a9e0-85c9-47b2-b77e-710d898277da",
   "metadata": {},
   "source": [
    "Anche in questo caso il grafico parla da sé. L'accurattezza, la precisione e il recall si mantengo *molto alti* nonostante parte della informazione originaria è andata perduta. In questo senso, la rappresentazione è più compatta. Inoltre, perdendo solo qualche punto di accuratezza, il calcolo risulta più veloce e meno dispendioso. Questa è una **pratica standard per l'uso nei dispositivi mobili o in IoT**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c93184-04ff-4f44-8b63-c073b1ae41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {100 * acc:.2f}%')\n",
    "\n",
    "pre = precision_score(y_test, y_pred, average='micro')\n",
    "print(f'Precision: {100 * pre:.2f}%')\n",
    "\n",
    "rec = recall_score(y_test, y_pred, average='micro')\n",
    "print(f'Recall: {100 * pre:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5bd5d-2dd4-4db7-86ca-f91288c71e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "p, r, _ = precision_recall_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_precision_recall(p, r, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aec44ab-7e25-4d6a-8286-4fb5f807215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test_dummy.ravel(), y_prob.ravel())\n",
    "score = roc_auc_score(y_test_dummy.ravel(), y_prob.ravel())\n",
    "\n",
    "_, ax = subplots()\n",
    "\n",
    "plot_roc_curve(fpr, tpr, score, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c167e9-54ca-4778-8750-5327fec96a83",
   "metadata": {},
   "source": [
    "Come in precedenza, il motivo del successo è da ricercare nel **modo** in cui le operazioni vengono svolte. La rappresentazione tramite PCA è *semplice* da suddividere. Analizzando il grafico sembrerebbe persino che anche un umano avrebbe avuto qualche difficoltà a tracciare i giusti contorni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c380e75-21fa-46e9-8e5c-8227b5f74b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(d_cp['pc_1'].min() - 0.5, d_cp['pc_1'].max() + 0.5, 0.1)\n",
    "y = np.arange(d_cp['pc_2'].min() - 0.5, d_cp['pc_2'].max() + 0.5, 0.1)\n",
    "x_grid, y_grid = np.meshgrid(x, y)\n",
    "grid = np.c_[x_grid.ravel(), y_grid.ravel()]\n",
    "bnd  = lr.predict(grid).reshape(x_grid.shape)\n",
    "\n",
    "fig, ax = subplots()\n",
    "\n",
    "c = ax.contourf(x_grid,\n",
    "                y_grid,\n",
    "                bnd,\n",
    "                levels=range(-1, 3),\n",
    "                colors=sns.color_palette(n_colors=3)[::-1],\n",
    "                alpha=0.3\n",
    "               )\n",
    "\n",
    "cbar = fig.colorbar(c, ticks=np.arange(3) - 0.5, ax=ax)\n",
    "cbar.set_ticklabels(names)\n",
    "\n",
    "sns.scatterplot(data=d_cp,\n",
    "                x='pc_1',\n",
    "                y='pc_2',\n",
    "                hue=y_pred.replace(names),\n",
    "                style=ident,\n",
    "                ax=ax\n",
    "               )\n",
    "\n",
    "ax.set(xlabel='PC 1', ylabel='PC 2', title='PCA + LogReg')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27370e94-e004-4cb7-869a-06e59f4c8473",
   "metadata": {},
   "source": [
    "## Intelligenza Artificiale?\n",
    "\n",
    "Passiamo ora a considerare un compito più *complicato*. Ci concentriamo sul **riconoscimento della grafia**, ossia il riconoscimento della scrittura a mano. Si tratta di un compito estremamente importante, che viene svolto ormai ovunque da cellulari, tablet, etc.\n",
    "\n",
    "In questa demo cercheremo di costruirlo per passi successivi, ricostruendo anche la *storia* di come questo problema è stato approacciato. Arriveremo poi a costruire un piccolo modello di AI capace di risolvere un problema **difficile da risolvere per un umano**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3abded-a353-4aa1-babd-116b4949247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X, y), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# pad to have 32 x 32 input\n",
    "X      = np.pad(X, ((0,0), (2,2), (2,2)))\n",
    "X_test = np.pad(X_test, ((0,0), (2,2), (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73625270-3ddd-4479-abf9-867c7c6574c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:10000, :, :] / 255.0\n",
    "X_train = X_train.reshape(X_train.shape + (1,))\n",
    "y_train = y[:10000]\n",
    "\n",
    "X_val   = X[10000:11000, :, :] / 255.0\n",
    "X_val   = X_val.reshape(X_val.shape + (1,))\n",
    "y_val   = y[10000:11000]\n",
    "\n",
    "X_test  = X_test[:1000, :, :] / 255.0\n",
    "X_test  = X_test.reshape(X_test.shape + (1,))\n",
    "y_test  = y_test[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33a042a-8863-4153-8156-72a0a8732a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oh = np.zeros((y_train.shape[0], 10))\n",
    "y_val_oh   = np.zeros((y_val.shape[0], 10))\n",
    "y_test_oh  = np.zeros((y_test.shape[0], 10))\n",
    "\n",
    "for n, v in enumerate(y_train):\n",
    "    \n",
    "    y_train_oh[n, v] = 1\n",
    "    \n",
    "for n, v in enumerate(y_val):\n",
    "    \n",
    "    y_val_oh[n, v] = 1\n",
    "    \n",
    "for n, v in enumerate(y_test):\n",
    "    \n",
    "    y_test_oh[n, v] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce58a49e-48a7-422b-8ff5-ed1bdc742c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(1, 5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_train[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_train[n]:d}')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f781a994-4b20-4506-8f5a-e9a7829f2f92",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Il primo passo è quello di provare a risolvere il problema come in precedenza, tramite una **regression logistica**. In pratica si tratta di:\n",
    "\n",
    "1. *vettorizzare* (o \"rendere piatti\") i numeri scritti a mano,\n",
    "2. data una certa *sequenza* di valori, calcolare **la probabilità che la sequenza rappresenti un dato numero**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae24573-7a4b-4dc4-a1bf-cfb950bfe4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flat = X_train.reshape(X_train.shape[0],-1)\n",
    "X_val_flat   = X_val.reshape(X_val.shape[0],-1)\n",
    "X_test_flat  = X_test.reshape(X_test.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf448978-a465-4be8-82e7-b77c2649117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_train_flat[n, :].reshape(1, -1),\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=False,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_train[n]:d}')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90235eaf-61f0-4351-bb6b-2558354e7dfe",
   "metadata": {},
   "source": [
    "Come stabilito, il primo passo è una curva logistica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53fcd8-79a6-404d-845e-73b8efbb3067",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=1.0e5, n_jobs=-1)\n",
    "lr = lr.fit(X_train_flat, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1991e0-7a45-4b48-8d16-4e5fe876b119",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test_flat)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score: {100 * acc:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c2f452-daae-43fb-af88-6e057d2e573a",
   "metadata": {},
   "source": [
    "In questo caso ci occupiamo solo della accuratezza, per semplicità (tenere conto anche di precisione e recall è *molto importante*, ma in questo momento sarebbe eccessivo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ef79e2-19ec-4e9a-939c-a8cbd567e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(1, 5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_test[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_test[n]:d}',\n",
    "              xlabel=f'predicted class: {y_pred[n]:d}'\n",
    "             )\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364ebdd5-4326-4e8e-a11b-4740bd7076c2",
   "metadata": {},
   "source": [
    "Il risultato è davvero molto soddisfacente. Per buona parte degli elementi cosiddetti *di test*, la predizione è corretta.\n",
    "\n",
    "Possiamo fare di meglio?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed235d6-c2b5-41c5-a3d8-6f21bd4765b0",
   "metadata": {},
   "source": [
    "### Multi-Layered Perceptron\n",
    "\n",
    "L'idea del **multi-layered perceptron** non è poi così nuova. Già nel 1957 Rosenblatt introdusse il *percettrone* come modello di apprendimento umano (in parte l'analogia reti neurali - cervello nasce da lì, anche se ciò che oggi chiamiamo *rete neurale* ha ben poco da spartire con il cervello umano).\n",
    "\n",
    "Il suo principio di funzionamento è basato su una struttura sovrapposta di **regressori logistici** (da qui la necessità di introdurre per primo il modello semplice):\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/dl-visuals/main/Feed-Forward%20Networks/feature_space_1hidden.png)\n",
    "\n",
    "I vantaggi di questa struttura sono molteplici:\n",
    "\n",
    "1. permette di **approssimare funzioni non lineari** (con alcuni accorgimenti, come le *attivazioni*) e molto complesse,\n",
    "2. ha una **derivata calcolabile**, per cui l'errore di approssimazione può essere propagato *indietro* e trasmesso ai coefficienti (**backpropagation**),\n",
    "3. crea automaticamente delle nuove variabili ad ogni livello in modo tale da decidere in autonomia quali sono più importanti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d467a2-87d0-4cd8-baee-b295ad54dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "mlp = Sequential([Dense(128, activation='relu', input_shape=(X_train_flat.shape[-1],)),\n",
    "                  BatchNormalization(),\n",
    "                  Dense(10, activation='softmax')\n",
    "                 ],\n",
    "                 name='mlp'\n",
    "                )\n",
    "\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f90f08-fe52-4869-ac49-886548b3e356",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_dot = model_to_dot(mlp, dpi=300)\n",
    "Image(mlp_dot.create_png(), width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89efc87e-40bf-45e8-8c25-3007181405c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.compile(optimizer=Adam(learning_rate=1.0e-3),\n",
    "            loss=CategoricalCrossentropy(from_logits=True),\n",
    "            metrics=[CategoricalAccuracy()]\n",
    "           )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cee5a-d067-4360-86e6-57fe30f12ae4",
   "metadata": {},
   "source": [
    "Il modello di rete neurale ha la necessità di essere \"allenato\" tramite una procedura iterativa su *epoche*. In pratica ad ogni epoca il modello \"tenta\" di fare delle predizioni e misura quanto queste sono *distanti* dalla verità. A questo punto apporta gli aggiustamenti necessari e ripete la procedura."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70920d55-7ab1-4a80-ba70-261f8650a531",
   "metadata": {},
   "outputs": [],
   "source": [
    "hst = mlp.fit(x=X_train_flat,\n",
    "              y=y_train_oh,\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_data=(X_val_flat, y_val_oh),\n",
    "              callbacks=[ModelCheckpoint('./mlp.h5', save_best_only=True)]\n",
    "             )\n",
    "\n",
    "mlp.load_weights('./mlp.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4af1c83-3ed5-4b73-bc9e-a14e52836f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=2)\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "ax[0].set(xlabel='epochs', ylabel='cross entropy')\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['categorical_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_categorical_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "ax[1].set(xlabel='epochs', ylabel='accuracy')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d3c547-5372-4dd0-a0d6-0e8092beec7b",
   "metadata": {},
   "source": [
    "Il salto di qualità è evidente, rispetto al suo corrispettivo machine learning \"semplice\". In questo modo le predizioni del modello sono molto più attendibili e possiamo anche cominciare a pensare di usare qualcosa di simile a livello \"industriale\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f04b178-157c-4dc3-bac1-71a2faba9aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = mlp.predict(X_test_flat)\n",
    "\n",
    "acc = accuracy_score(y_test, np.argmax(y_pred, axis=1))\n",
    "print(f'Accuracy score: {100 * acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e89f0-d9d0-4fee-97d8-462787427db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(1, 5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_test[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_test[n]:d}',\n",
    "              xlabel=f'predicted class: {np.argmax(y_pred, axis=1)[n]:d}'\n",
    "             )\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b338477e-730f-4285-93b1-97d6b9419258",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network\n",
    "\n",
    "Le possibilità non sono finite qui, tuttavia. In realtà, qualunque funzione **la cui derivata è calcolabile** permette di \"allenare\" una rete neurale. E alcune funzioni sono molto meglio di altre.\n",
    "\n",
    "Nel 1989, Yann LeCun (ora *chief scientist* presso Facebook AI) introduce le **reti neurali convoluzionali** (in Inglese, *Convolutional Neural Network*). L'idea è ben spiegata usando un'analogia con la fisica e lo studio dei segnali:\n",
    "\n",
    "![](https://www.ligo.org/science/Publication-S6PE/Images/wave_examples_noise.gif)\n",
    "*da [LIGO Scientific Collaboration](https://www.ligo.org/science/Publication-S6PE/index.php)*\n",
    "\n",
    "Una convoluzione è un'operazione che può essere usata, ad esempio, per cercare un segnale di una specifica forma:\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/c/c6/Convolucion_Funcion_Pi.gif)\n",
    "*da [WikiMedia](https://upload.wikimedia.org/wikipedia/commons/c/c6/Convolucion_Funcion_Pi.gif)*\n",
    "\n",
    "Questa operazione può essere eseguita anche su immagini se necessario (e nel nostro case, questo è ciò di cui abbiamo bisogno):\n",
    "\n",
    "![](https://miro.medium.com/max/2340/1*Fw-ehcNBR9byHtho-Rxbtw.gif)\n",
    "*da [Irhum Shafkat](https://towardsdatascience.com/intuitively-understanding-convolutions-for-deep-learning-1f6f42faee1)*\n",
    "\n",
    "L'idea in una rete neurale di questo tipo è che **pixel vicini condividono dei parametri**, ossia permettono di recuperare il significato di piccole porzioni di immagini:\n",
    "\n",
    "![](https://raw.githubusercontent.com/dvgodoy/dl-visuals/main/Convolutions/conv3.png)\n",
    "*da [dvgodoy](https://github.com/dvgodoy/dl-visuals)*\n",
    "\n",
    "In questo senso, una rete neurale convoluzionale **vede come un umano** e decide come caratterizzare l'input basandosi su ciò che seleziona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0a7cc-65a4-4630-a444-a70c07c4e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "cnn = Sequential([Conv2D(filters=128, kernel_size=(3,3), activation='relu', input_shape=(None, None, 1)),\n",
    "                  BatchNormalization(),\n",
    "                  MaxPool2D(pool_size=(2,2)),\n",
    "                  Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "                  BatchNormalization(),\n",
    "                  MaxPool2D(pool_size=(2,2)),\n",
    "                  Dropout(rate=0.25),\n",
    "                  Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "                  BatchNormalization(),\n",
    "                  MaxPool2D(pool_size=(2,2)),\n",
    "                  Conv2D(filters=32, kernel_size=(2,2), activation='relu'),\n",
    "                  BatchNormalization(),\n",
    "                  Dropout(rate=0.25),\n",
    "                  Conv2D(filters=10, kernel_size=(1,1)),\n",
    "                  Activation('softmax')\n",
    "                 ],\n",
    "                 name='cnn'\n",
    "                )\n",
    "\n",
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c553c7-d6a8-46e4-b626-0b0020035a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_dot = model_to_dot(cnn, dpi=300)\n",
    "Image(cnn_dot.create_png(), width=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233285f-e0bc-44f1-a423-e9d1f23dfc9a",
   "metadata": {},
   "source": [
    "Anche in questo caso l'apprendimento avviene iterativamente, esattamente nello stesso modo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364a51af-f1e0-45d4-9a2c-30e7d0c23d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer=Adam(learning_rate=1.0e-3),\n",
    "            loss=CategoricalCrossentropy(),\n",
    "            metrics=[CategoricalAccuracy()]\n",
    "           )\n",
    "\n",
    "hst = cnn.fit(x=X_train,\n",
    "              y=y_train_oh.reshape(y_train_oh.shape[0], 1, 1, y_train_oh.shape[-1]),\n",
    "              batch_size=32,\n",
    "              epochs=10,\n",
    "              validation_data=(X_val, y_val_oh.reshape(y_val_oh.shape[0], 1, 1, y_val_oh.shape[-1])),\n",
    "              callbacks=[ModelCheckpoint('./cnn.h5', save_best_only=True)]\n",
    "             )\n",
    "\n",
    "cnn.load_weights('./cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba53595-79a4-4138-bdb1-97d5a3bedae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=2)\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "ax[0].set(xlabel='epochs', ylabel='cross entropy')\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['categorical_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_categorical_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "ax[1].set(xlabel='epochs', ylabel='accuracy')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4d99a7-aa37-4f51-a996-8b3493b4f2ea",
   "metadata": {},
   "source": [
    "E ancora una volta arriviamo ad ottenere un incremento di accuratezza dovuto all'abilità della rete di riconoscere particolari a partire direttamente dall'immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed01c1e-ed13-4124-ae93-6ec204f2c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = cnn.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, np.argmax(y_pred, axis=-1).ravel())\n",
    "print(f'Accuracy score: {100 * acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f48d047-39f0-4102-b10c-46365e3abb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(1, 5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_test[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_test[n]:d}',\n",
    "              xlabel=f'predicted class: {np.argmax(y_pred, axis=-1).ravel()[n]:d}'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57db33b4-32f6-4ddd-b82a-24bf79bcecc4",
   "metadata": {},
   "source": [
    "Un altro **enorme vantaggio** di queste reti è la loro indipendenza dalla dimensione dell'input: questo significa che le loro applicazioni sono pressoché infinite ed estremamente versatili."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb59863-de08-42b8-a15a-7959d1dd7e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "\n",
    "    conc = np.concatenate([X_test[n], X_test[n + 1]], axis=1)\n",
    "    conc = conc.reshape(1, conc.shape[0], conc.shape[1], conc.shape[2])\n",
    "\n",
    "    sns.heatmap(data=conc[0, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    pred = np.argmax(cnn.predict(conc), axis=-1).reshape(-1,)   \n",
    "    \n",
    "    ax[n].set(xlabel=f'predicted class: {pred[0]:d}{pred[-1]:d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c86ca71-367f-4dcc-b7c4-f2ce6e12c60f",
   "metadata": {},
   "source": [
    "### Autoencoder\n",
    "\n",
    "Questo rappresenta un ultimo step prima di un modello di AI completo. Supponiamo di avere un **problema reale**: dovete riconoscere delle cifre scritte a mano ma queste sono **corrotte da molto rumore**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58941f27-bc12-4132-93c6-25d38651ad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_noise = X_train + 2.0 * np.random.uniform(size=X_train.shape)\n",
    "X_val_noise   = X_val + 2.0 * np.random.uniform(size=X_val.shape)\n",
    "X_test_noise  = X_test + 2.0 * np.random.uniform(size=X_test.shape)\n",
    "\n",
    "tmp_pred = cnn.predict(X_train_noise)\n",
    "\n",
    "_, ax = subplots(ncols=5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_train_noise[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    ax[n].set(title=f'target class: {y_train[n]:d}',\n",
    "              xlabel=f'predicted class: {np.argmax(tmp_pred, axis=-1).ravel()[n]:d}'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895d43b9-56d8-4adf-aa3f-4fcc5de7dabf",
   "metadata": {},
   "source": [
    "Come si può notare, il nostro semplice modello di rete neurale precedente non riesce a predire nulla. E, ad essere sinceri, anche un umano potrebbe avere seri problemi a capire quali numeri si celano dietro tanto rumore.\n",
    "\n",
    "Un architettura di tipo **autoencoder** è un metodo **unsupervised** basato su reti neurali che permette, come già visto, di riorganizzare l'input in modo tale da ricostruire una rappresentazione **migliore di quella di partenza**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1699de27-b3a8-43bd-b9d5-0b135fad3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "aenc = Sequential([Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', input_shape=(None, None, 1)),\n",
    "                   MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "                   Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "                   MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "                   Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "                   MaxPool2D(pool_size=(2,2), padding='same'),\n",
    "                   Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "                   UpSampling2D(size=(2,2)),\n",
    "                   Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "                   UpSampling2D(size=(2,2)),\n",
    "                   Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu'),\n",
    "                   UpSampling2D(size=(2,2)),\n",
    "                   Conv2D(filters=1, kernel_size=(3,3), padding='same', activation='sigmoid'),\n",
    "                  ],\n",
    "                  name='autoencoder'\n",
    "                 )\n",
    "\n",
    "aenc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2715e12e-471d-4b5c-8d6e-1d0dc14d7023",
   "metadata": {},
   "outputs": [],
   "source": [
    "aenc_dot = model_to_dot(aenc, dpi=300)\n",
    "Image(aenc_dot.create_png(), width=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805e8392-9f35-4875-9ecb-a0f02fe4f11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "aenc.compile(optimizer=Adam(learning_rate=1.0e-3),\n",
    "            loss=BinaryCrossentropy(),\n",
    "            metrics=[BinaryAccuracy()]\n",
    "           )\n",
    "\n",
    "hst = aenc.fit(x=X_train_noise,\n",
    "               y=X_train,\n",
    "               batch_size=32,\n",
    "               epochs=10,\n",
    "               validation_data=(X_val_noise, X_val),\n",
    "               callbacks=[ModelCheckpoint('./aenc.h5', save_best_only=True)]\n",
    "             )\n",
    "\n",
    "aenc.load_weights('./aenc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97657be1-1525-43c4-ab78-7daeeef10070",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=2)\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_loss'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[0]\n",
    "            )\n",
    "\n",
    "ax[0].set(xlabel='epochs', ylabel='cross entropy')\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['binary_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:blue',\n",
    "             label='training',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "sns.lineplot(x=range(1, 11),\n",
    "             y=hst.history['val_binary_accuracy'],\n",
    "             linestyle='-',\n",
    "             color='tab:red',\n",
    "             label='validation',\n",
    "             ax=ax[1]\n",
    "            )\n",
    "\n",
    "ax[1].set(xlabel='epochs', ylabel='accuracy')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b09288-2506-4e54-b43a-3dc9af62305e",
   "metadata": {},
   "source": [
    "I risultati sono molto positivi. La rete neurale è in grado di capire bene la distribuzione del rumore che copre i numeri scritti a mano e permette la ricostruzione delle cifre in maniera quasi perfetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91403a7-9332-475a-811d-9473ac113648",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = aenc.predict(X_test_noise)\n",
    "\n",
    "_, ax = subplots(nrows=3, ncols=5, sharey=True, sharex=True)\n",
    "\n",
    "for n in range(5):\n",
    "    \n",
    "    sns.heatmap(data=X_test_noise[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[0, n]\n",
    "               )\n",
    "    \n",
    "    sns.heatmap(data=X_test[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[1, n]\n",
    "               )\n",
    "    \n",
    "    sns.heatmap(data=preds[n, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[2, n]\n",
    "               )\n",
    "\n",
    "ax[0, 0].set_ylabel('Noisy Data');\n",
    "ax[1, 0].set_ylabel('Original Data');\n",
    "ax[2, 0].set_ylabel('Denoised Data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462f02a5-c024-42ae-8b74-5eee674fbd54",
   "metadata": {},
   "source": [
    "E come al solito, possiamo anche avere input di dimensioni diverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f3797-7def-4a7a-a338-050769c2389d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(nrows=2, ncols=5, sharex=True, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "\n",
    "    conc_noise = np.concatenate([X_test_noise[n], X_test_noise[n + 1]], axis=1)\n",
    "    conc_noise = conc_noise.reshape(1, conc_noise.shape[0], conc_noise.shape[1], conc_noise.shape[2])\n",
    "\n",
    "    sns.heatmap(data=conc_noise[0, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[0, n]\n",
    "               )\n",
    "    \n",
    "    pred = aenc.predict(conc_noise)\n",
    "    \n",
    "    sns.heatmap(data=pred[0, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[1, n]\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddbd288-ebb9-4297-9a2c-b39a875a0bea",
   "metadata": {},
   "source": [
    "### AI Recognition\n",
    "\n",
    "Siamo, a questo punto, pronti a creare il primo modellino di AI in grado di:\n",
    "\n",
    "1. \"dare un'occhiata\" alle cifre e assegnare una classe,\n",
    "2. \"pulire\" i dati in ingresso se necessario per permettere una migliore classificazione,\n",
    "3. essere versatile sulla dimensione di input,\n",
    "4. *molto probabilmente* battere in accuratezza anche un essere umano particolarmente attento (di sicuro è più veloce).\n",
    "\n",
    "Interessante da notare, ciò che abbiamo implementato qui è un primo esempio (semplificato) di un algoritmo di tipo YOLO (= *You Only Look Once*), in grado di restituire il valore della classe corrispondente ad un particolare filtro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5839f74f-6c62-41d9-bfe8-84a10b903669",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "ai = Model(inputs=aenc.input, outputs=cnn(aenc.output), trainable=False, name='ai_recognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47824036-d943-46ed-b64e-3f38fd505c42",
   "metadata": {},
   "source": [
    "Come possiamo notare l'accuratezza non è ai livelli del modello con l'input *pulito*, ma è comunque estremamente competitivo e permette di \"fidarsi\" delle predizioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252f0360-c534-4532-826e-73085a14bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.argmax(ai.predict(X_test_noise), axis=-1).ravel()\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy score: {100 * acc:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4ca49-d6af-483a-a120-445d8d443903",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = subplots(ncols=5, sharey=True)\n",
    "\n",
    "for n in range(5):\n",
    "\n",
    "    conc_noise = np.concatenate([X_test_noise[n], X_test_noise[n + 1]], axis=1)\n",
    "    conc_noise = conc_noise.reshape(1, conc_noise.shape[0], conc_noise.shape[1], conc_noise.shape[2])\n",
    "    \n",
    "    labels = y_test[n] * 10 + y_test[n + 1]\n",
    "\n",
    "    sns.heatmap(data=conc_noise[0, :, :, 0],\n",
    "                cmap='Greys_r',\n",
    "                cbar=False,\n",
    "                xticklabels=False,\n",
    "                yticklabels=False,\n",
    "                square=True,\n",
    "                ax=ax[n]\n",
    "               )\n",
    "    \n",
    "    pred = np.argmax(ai.predict(conc_noise), axis=-1).reshape(-1,)\n",
    "    \n",
    "    ax[n].set_title(f'actual class: {labels:d}')\n",
    "    ax[n].set_xlabel(f'predicted class: {pred[0]:d}{pred[-1]:d}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
